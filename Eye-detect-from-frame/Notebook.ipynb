{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Video Detection using eye blinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"Notebook.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Blink and Eye Aspect Ratio calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate eye aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distance between the vertical eye landmarks\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal eye landmarks\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the EAR\n",
    "    ear = (A + B) / (2 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "EYE_AR_THRESH = 0.22\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "EAR_AVG = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Blinks in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create a OpenCV window\n",
    "def count_blinks(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    # capture frame from local video\n",
    "    # cap = cv2.VideoCapture(\"Home/Eye-detect-from-frame/download.jpeg\")\n",
    "    # capture video from live facecam\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if frame is not []:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return TOTAL\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "\n",
    "                cv2.putText(frame, \"Blinks {}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "                cv2.putText(frame, \"EAR {}\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "            cv2.imshow(\"Winks Found\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            # When key 'Q' is pressed, exit\n",
    "            if key is ord('q'):\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return TOTAL\n",
    "                break\n",
    "        else:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(str(TOTAL)+\" blinks found\")\n",
    "            return TOTAL\n",
    "    # release all resources\n",
    "    cap.release()\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blinks found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_blinks(\"deepfake.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id7_0001.mp4',\n",
       " 'id12_0006.mp4',\n",
       " 'id11_0007.mp4',\n",
       " 'id7_0007.mp4',\n",
       " 'id17_0005.mp4',\n",
       " 'id3_0003.mp4',\n",
       " 'id8_0004.mp4',\n",
       " 'id3_0005.mp4',\n",
       " 'id3_0006.mp4',\n",
       " 'id12_0000.mp4',\n",
       " 'id13_0009.mp4',\n",
       " 'id10_0003.mp4',\n",
       " 'id13_0001.mp4',\n",
       " 'id0_0008.mp4',\n",
       " 'id0_0004.mp4',\n",
       " 'id8_0006.mp4',\n",
       " 'id17_0001.mp4',\n",
       " 'id7_0002.mp4',\n",
       " 'id0_0001.mp4',\n",
       " 'id7_0004.mp4',\n",
       " 'id6_0004.mp4',\n",
       " 'id17_0000.mp4',\n",
       " 'id11_0006.mp4',\n",
       " 'id2_0006.mp4',\n",
       " 'id11_0008.mp4',\n",
       " 'id16_0003.mp4',\n",
       " 'id6_0001.mp4',\n",
       " 'id16_0008.mp4',\n",
       " 'id2_0004.mp4',\n",
       " 'id3_0001.mp4',\n",
       " 'id13_0010.mp4',\n",
       " 'id12_0001.mp4',\n",
       " 'id16_0005.mp4',\n",
       " 'id4_0003.mp4',\n",
       " 'id16_0004.mp4',\n",
       " 'id8_0007.mp4',\n",
       " 'id13_0015.mp4',\n",
       " 'id2_0009.mp4',\n",
       " 'id13_0003.mp4',\n",
       " 'id9_0001.mp4',\n",
       " 'id11_0004.mp4',\n",
       " 'id13_0007.mp4',\n",
       " 'id2_0000.mp4',\n",
       " 'id8_0005.mp4',\n",
       " 'id2_0008.mp4',\n",
       " 'id11_0002.mp4',\n",
       " 'id0_0007.mp4',\n",
       " 'id12_0004.mp4',\n",
       " 'id6_0006.mp4',\n",
       " 'id10_0009.mp4',\n",
       " 'id1_0008.mp4',\n",
       " 'id17_0002.mp4',\n",
       " 'id7_0008.mp4',\n",
       " 'id1_0006.mp4',\n",
       " 'id2_0002.mp4',\n",
       " 'id4_0000.mp4',\n",
       " 'id9_0007.mp4',\n",
       " 'id17_0006.mp4',\n",
       " 'id2_0003.mp4',\n",
       " 'id1_0007.mp4',\n",
       " 'id13_0005.mp4',\n",
       " 'id9_0008.mp4',\n",
       " 'id1_0003.mp4',\n",
       " 'id3_0002.mp4',\n",
       " 'id17_0007.mp4',\n",
       " 'id16_0001.mp4',\n",
       " 'id6_0002.mp4',\n",
       " 'id6_0007.mp4',\n",
       " 'id13_0002.mp4',\n",
       " 'id10_0005.mp4',\n",
       " 'id13_0008.mp4',\n",
       " 'id8_0002.mp4',\n",
       " 'id6_0005.mp4',\n",
       " 'id10_0004.mp4',\n",
       " 'id8_0003.mp4',\n",
       " 'id4_0009.mp4',\n",
       " 'id10_0000.mp4',\n",
       " 'id2_0001.mp4',\n",
       " 'id16_0013.mp4',\n",
       " 'id6_0008.mp4',\n",
       " 'id17_0008.mp4',\n",
       " 'id1_0001.mp4',\n",
       " 'id0_0006.mp4',\n",
       " 'id16_0007.mp4',\n",
       " 'id3_0009.mp4',\n",
       " 'id4_0002.mp4',\n",
       " 'id12_0005.mp4',\n",
       " 'id4_0001.mp4',\n",
       " 'id16_0011.mp4',\n",
       " 'id8_0001.mp4',\n",
       " 'id9_0006.mp4',\n",
       " 'id16_0002.mp4',\n",
       " 'id4_0008.mp4',\n",
       " 'id0_0009.mp4',\n",
       " 'id0_0000.mp4',\n",
       " 'id0_0003.mp4',\n",
       " 'id17_0003.mp4',\n",
       " 'id7_0006.mp4',\n",
       " 'id11_0010.mp4',\n",
       " 'id11_0001.mp4',\n",
       " 'id9_0002.mp4',\n",
       " 'id3_0004.mp4',\n",
       " 'id8_0000.mp4',\n",
       " 'id10_0008.mp4',\n",
       " 'id13_0004.mp4',\n",
       " 'id6_0009.mp4',\n",
       " 'id11_0005.mp4',\n",
       " 'id1_0002.mp4',\n",
       " 'id13_0006.mp4',\n",
       " 'id7_0000.mp4',\n",
       " 'id4_0004.mp4',\n",
       " 'id9_0005.mp4',\n",
       " 'id6_0003.mp4',\n",
       " 'id10_0006.mp4',\n",
       " 'id3_0008.mp4',\n",
       " 'id12_0003.mp4',\n",
       " 'id13_0000.mp4',\n",
       " 'id9_0000.mp4',\n",
       " 'id7_0005.mp4',\n",
       " 'id1_0000.mp4',\n",
       " 'id13_0013.mp4',\n",
       " 'id9_0009.mp4',\n",
       " 'id16_0010.mp4',\n",
       " 'id8_0009.mp4',\n",
       " 'id1_0009.mp4',\n",
       " 'id0_0005.mp4',\n",
       " 'id16_0012.mp4',\n",
       " 'id1_0004.mp4',\n",
       " 'id4_0007.mp4',\n",
       " 'id7_0009.mp4',\n",
       " 'id4_0005.mp4',\n",
       " 'id9_0003.mp4',\n",
       " 'id11_0000.mp4',\n",
       " 'id9_0004.mp4',\n",
       " 'id10_0001.mp4',\n",
       " 'id11_0009.mp4',\n",
       " 'id3_0000.mp4',\n",
       " 'id17_0009.mp4',\n",
       " 'id13_0011.mp4',\n",
       " 'id11_0003.mp4',\n",
       " 'id2_0005.mp4',\n",
       " 'id3_0007.mp4',\n",
       " 'id16_0006.mp4',\n",
       " 'id7_0003.mp4',\n",
       " 'id10_0002.mp4',\n",
       " 'id4_0006.mp4',\n",
       " 'id13_0012.mp4',\n",
       " 'id16_0000.mp4',\n",
       " 'id17_0004.mp4',\n",
       " 'id8_0008.mp4',\n",
       " 'id1_0005.mp4',\n",
       " 'id2_0007.mp4',\n",
       " 'id16_0009.mp4',\n",
       " 'id10_0007.mp4',\n",
       " 'id12_0002.mp4',\n",
       " 'id6_0000.mp4',\n",
       " 'id0_0002.mp4',\n",
       " 'id13_0014.mp4']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating EAR of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create a OpenCV window\n",
    "def avg_ear(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "    EAR = 0\n",
    "    n=0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    # capture frame from local video\n",
    "    # cap = cv2.VideoCapture(\"Home/Eye-detect-from-frame/download.jpeg\")\n",
    "    # capture video from live facecam\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if (frame is not []) & ret == True:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(EAR/n)+\" is the average EAR of this video\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return (EAR/n)\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                EAR+= ear_avg\n",
    "                n+=1\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "\n",
    "                cv2.putText(frame, \"Blinks {}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "                cv2.putText(frame, \"EAR {}\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "            cv2.imshow(\"Winks Found\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            # When key 'Q' is pressed, exit\n",
    "            if key is ord('q'):\n",
    "                print(\"Total no. of blinks are\",TOTAL)\n",
    "                break\n",
    "        else:\n",
    "            print(str(EAR/n)+\" is the average EAR of this video\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return (EAR/n)\n",
    "            break\n",
    "    # release all resources\n",
    "    cap.release()\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_ear(\"1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_blinks(\"1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blinks_ear(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "    EAR = 0\n",
    "    n=0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) \n",
    "    duration = int(frames / fps)\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if frame is not []:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return (TOTAL,EAR/n,duration)\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                EAR+= ear_avg\n",
    "                n+=1\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "        else:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return (TOTAL,EAR/n,duration)\n",
    "    # release all resources\n",
    "    cap.release()\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_blinks_ear(\"trump.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 blinks found\n",
      "0 blinks found\n",
      "3 blinks found\n",
      "4 blinks found\n",
      "10 blinks found\n",
      "7 blinks found\n",
      "0 blinks found\n",
      "7 blinks found\n",
      "6 blinks found\n",
      "0 blinks found\n",
      "5 blinks found\n",
      "3 blinks found\n",
      "1 blinks found\n",
      "10 blinks found\n",
      "3 blinks found\n",
      "2 blinks found\n",
      "17 blinks found\n",
      "1 blinks found\n",
      "5 blinks found\n",
      "7 blinks found\n",
      "0 blinks found\n",
      "1 blinks found\n",
      "4 blinks found\n",
      "5 blinks found\n",
      "11 blinks found\n",
      "8 blinks found\n",
      "4 blinks found\n",
      "10 blinks found\n",
      "5 blinks found\n",
      "2 blinks found\n",
      "0 blinks found\n",
      "0 blinks found\n",
      "9 blinks found\n",
      "3 blinks found\n",
      "14 blinks found\n",
      "0 blinks found\n",
      "5 blinks found\n",
      "11 blinks found\n",
      "4 blinks found\n",
      "7 blinks found\n",
      "3 blinks found\n",
      "4 blinks found\n",
      "9 blinks found\n",
      "0 blinks found\n",
      "7 blinks found\n",
      "6 blinks found\n",
      "12 blinks found\n",
      "4 blinks found\n",
      "0 blinks found\n",
      "3 blinks found\n",
      "4 blinks found\n",
      "16 blinks found\n",
      "6 blinks found\n",
      "12 blinks found\n",
      "6 blinks found\n",
      "18 blinks found\n",
      "6 blinks found\n",
      "3 blinks found\n",
      "5 blinks found\n",
      "8 blinks found\n",
      "2 blinks found\n",
      "12 blinks found\n",
      "17 blinks found\n",
      "1 blinks found\n",
      "6 blinks found\n",
      "11 blinks found\n",
      "0 blinks found\n",
      "0 blinks found\n",
      "5 blinks found\n",
      "7 blinks found\n",
      "5 blinks found\n",
      "7 blinks found\n",
      "0 blinks found\n",
      "3 blinks found\n",
      "7 blinks found\n",
      "10 blinks found\n",
      "0 blinks found\n",
      "5 blinks found\n",
      "6 blinks found\n",
      "1 blinks found\n",
      "3 blinks found\n",
      "2 blinks found\n",
      "3 blinks found\n",
      "3 blinks found\n",
      "4 blinks found\n",
      "13 blinks found\n",
      "4 blinks found\n",
      "16 blinks found\n",
      "4 blinks found\n",
      "3 blinks found\n",
      "10 blinks found\n",
      "5 blinks found\n",
      "5 blinks found\n",
      "17 blinks found\n",
      "10 blinks found\n",
      "17 blinks found\n",
      "4 blinks found\n",
      "2 blinks found\n",
      "8 blinks found\n",
      "4 blinks found\n",
      "7 blinks found\n",
      "13 blinks found\n",
      "0 blinks found\n",
      "0 blinks found\n",
      "6 blinks found\n",
      "4 blinks found\n",
      "2 blinks found\n",
      "5 blinks found\n",
      "9 blinks found\n",
      "6 blinks found\n",
      "1 blinks found\n",
      "11 blinks found\n",
      "0 blinks found\n",
      "0 blinks found\n",
      "18 blinks found\n",
      "2 blinks found\n",
      "1 blinks found\n",
      "15 blinks found\n",
      "1 blinks found\n",
      "13 blinks found\n",
      "2 blinks found\n",
      "5 blinks found\n",
      "11 blinks found\n",
      "6 blinks found\n",
      "11 blinks found\n",
      "6 blinks found\n",
      "4 blinks found\n",
      "13 blinks found\n",
      "11 blinks found\n",
      "9 blinks found\n",
      "5 blinks found\n",
      "14 blinks found\n",
      "8 blinks found\n",
      "3 blinks found\n",
      "0 blinks found\n",
      "4 blinks found\n",
      "9 blinks found\n",
      "5 blinks found\n",
      "11 blinks found\n",
      "8 blinks found\n",
      "0 blinks found\n",
      "2 blinks found\n",
      "4 blinks found\n",
      "6 blinks found\n",
      "1 blinks found\n",
      "9 blinks found\n",
      "4 blinks found\n",
      "7 blinks found\n",
      "0 blinks found\n",
      "13 blinks found\n",
      "4 blinks found\n",
      "0 blinks found\n",
      "16 blinks found\n",
      "5 blinks found\n",
      "0 blinks found\n",
      "2 blinks found\n",
      "13 blinks found\n",
      "2 blinks found\n"
     ]
    }
   ],
   "source": [
    "arr = os.listdir('./Celeb-DF/Celeb-real')\n",
    "\n",
    "df = pd.DataFrame(columns = ['Name', 'Blinks','Average_EAR','FakeOReal','Duration']) \n",
    "\n",
    "for i,name in enumerate(arr):\n",
    "#     if(i>=5):\n",
    "#         break\n",
    "    path = \"./Celeb-DF/Celeb-real/\"+str(name)\n",
    "    a=count_blinks_ear(path)\n",
    "    new_row = {'Name':name, 'Blinks':a[0],'Average_EAR':a[1],'FakeOReal':'Real','Duration':a[2]}\n",
    "    df= df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Blinks</th>\n",
       "      <th>Average_EAR</th>\n",
       "      <th>FakeOReal</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id7_0001.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.296071</td>\n",
       "      <td>Real</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id12_0006.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336012</td>\n",
       "      <td>Real</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11_0007.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.334730</td>\n",
       "      <td>Real</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id7_0007.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.305010</td>\n",
       "      <td>Real</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id17_0005.mp4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.254423</td>\n",
       "      <td>Real</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>id10_0007.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.334236</td>\n",
       "      <td>Real</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>id12_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357227</td>\n",
       "      <td>Real</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>id6_0000.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.336176</td>\n",
       "      <td>Real</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>id0_0002.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.197223</td>\n",
       "      <td>Real</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>id13_0014.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>Real</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Blinks  Average_EAR FakeOReal Duration\n",
       "0     id7_0001.mp4      4     0.296071      Real        9\n",
       "1    id12_0006.mp4      0     0.336012      Real       10\n",
       "2    id11_0007.mp4      3     0.334730      Real       10\n",
       "3     id7_0007.mp4      4     0.305010      Real       13\n",
       "4    id17_0005.mp4     10     0.254423      Real       10\n",
       "..             ...    ...          ...       ...      ...\n",
       "153  id10_0007.mp4      5     0.334236      Real       16\n",
       "154  id12_0002.mp4      0     0.357227      Real       12\n",
       "155   id6_0000.mp4      2     0.336176      Real       21\n",
       "156   id0_0002.mp4     13     0.197223      Real       11\n",
       "157  id13_0014.mp4      2     0.332709      Real       13\n",
       "\n",
       "[158 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DF-real.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
