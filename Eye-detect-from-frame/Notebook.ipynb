{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Video Detection using eye blinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"Notebook.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Blink and Eye Aspect Ratio calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate eye aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distance between the vertical eye landmarks\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal eye landmarks\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the EAR\n",
    "    ear = (A + B) / (2 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "EYE_AR_THRESH = 0.22\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "EAR_AVG = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Blinks in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create a OpenCV window\n",
    "def count_blinks(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    # capture frame from local video\n",
    "    # cap = cv2.VideoCapture(\"Home/Eye-detect-from-frame/download.jpeg\")\n",
    "    # capture video from live facecam\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if frame is not []:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return TOTAL\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "\n",
    "                cv2.putText(frame, \"Blinks {}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "                cv2.putText(frame, \"EAR {}\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "            cv2.imshow(\"Winks Found\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            # When key 'Q' is pressed, exit\n",
    "            if key is ord('q'):\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return TOTAL\n",
    "                break\n",
    "        else:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(str(TOTAL)+\" blinks found\")\n",
    "            return TOTAL\n",
    "    # release all resources\n",
    "    cap.release()\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_blinks(\"deepfake.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating EAR of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create a OpenCV window\n",
    "def avg_ear(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "    EAR = 0\n",
    "    n=0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    # capture frame from local video\n",
    "    # cap = cv2.VideoCapture(\"Home/Eye-detect-from-frame/download.jpeg\")\n",
    "    # capture video from live facecam\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if (frame is not []) & ret == True:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(EAR/n)+\" is the average EAR of this video\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return (EAR/n)\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                EAR+= ear_avg\n",
    "                n+=1\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "\n",
    "                cv2.putText(frame, \"Blinks {}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "                cv2.putText(frame, \"EAR {}\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "            cv2.imshow(\"Winks Found\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            # When key 'Q' is pressed, exit\n",
    "            if key is ord('q'):\n",
    "                print(\"Total no. of blinks are\",TOTAL)\n",
    "                break\n",
    "        else:\n",
    "            print(str(EAR/n)+\" is the average EAR of this video\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return (EAR/n)\n",
    "            break\n",
    "    # release all resources\n",
    "    cap.release()\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_ear(\"1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_blinks(\"1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blinks_ear(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "    EAR = 0\n",
    "    n=0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) \n",
    "    duration = int(frames / fps)\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if frame is not []:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return (TOTAL,EAR/n,duration)\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                EAR+= ear_avg\n",
    "                n+=1\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "        else:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return (TOTAL,EAR/n,duration)\n",
    "    # release all resources\n",
    "    cap.release()\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_blinks_ear(\"trump.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = os.listdir('./Celeb-DF/Celeb-real')\n",
    "\n",
    "df = pd.DataFrame(columns = ['Name', 'Blinks','Average_EAR','FakeOReal','Duration']) \n",
    "\n",
    "for i,name in enumerate(arr):\n",
    "#     if(i>=5):\n",
    "#         break\n",
    "    path = \"./Celeb-DF/Celeb-real/\"+str(name)\n",
    "    a=count_blinks_ear(path)\n",
    "    new_row = {'Name':name, 'Blinks':a[0],'Average_EAR':a[1],'FakeOReal':'Real','Duration':a[2]}\n",
    "    df= df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Blinks</th>\n",
       "      <th>Average_EAR</th>\n",
       "      <th>FakeOReal</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id7_0001.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.296071</td>\n",
       "      <td>Real</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id12_0006.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336012</td>\n",
       "      <td>Real</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11_0007.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.334730</td>\n",
       "      <td>Real</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id7_0007.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.305010</td>\n",
       "      <td>Real</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id17_0005.mp4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.254423</td>\n",
       "      <td>Real</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>id10_0007.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.334236</td>\n",
       "      <td>Real</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>id12_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357227</td>\n",
       "      <td>Real</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>id6_0000.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.336176</td>\n",
       "      <td>Real</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>id0_0002.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.197223</td>\n",
       "      <td>Real</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>id13_0014.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>Real</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Blinks  Average_EAR FakeOReal Duration\n",
       "0     id7_0001.mp4      4     0.296071      Real        9\n",
       "1    id12_0006.mp4      0     0.336012      Real       10\n",
       "2    id11_0007.mp4      3     0.334730      Real       10\n",
       "3     id7_0007.mp4      4     0.305010      Real       13\n",
       "4    id17_0005.mp4     10     0.254423      Real       10\n",
       "..             ...    ...          ...       ...      ...\n",
       "153  id10_0007.mp4      5     0.334236      Real       16\n",
       "154  id12_0002.mp4      0     0.357227      Real       12\n",
       "155   id6_0000.mp4      2     0.336176      Real       21\n",
       "156   id0_0002.mp4     13     0.197223      Real       11\n",
       "157  id13_0014.mp4      2     0.332709      Real       13\n",
       "\n",
       "[158 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DF-real.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in df['Blinks']:\n",
    "    if i == 1:\n",
    "        count += 1 \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = os.listdir('./Celeb-DF/Celeb-synthesis')\n",
    "\n",
    "df2 = pd.DataFrame(columns = ['Name', 'Blinks','Average_EAR','FakeOReal','Duration']) \n",
    "\n",
    "for i,name in enumerate(arr):\n",
    "    path = \"./Celeb-DF/Celeb-synthesis/\"+str(name)\n",
    "    a=count_blinks_ear(path)\n",
    "    new_row = {'Name':name, 'Blinks':a[0],'Average_EAR':a[1],'FakeOReal':'Fake','Duration':a[2]}\n",
    "    df2= df2.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Blinks</th>\n",
       "      <th>Average_EAR</th>\n",
       "      <th>FakeOReal</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id1_id3_0004.mp4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.262394</td>\n",
       "      <td>Fake</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id3_id6_0008.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294461</td>\n",
       "      <td>Fake</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id4_id2_0009.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.300553</td>\n",
       "      <td>Fake</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id9_id2_0007.mp4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.261735</td>\n",
       "      <td>Fake</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id13_id10_0000.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380302</td>\n",
       "      <td>Fake</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>id3_id17_0005.mp4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.244996</td>\n",
       "      <td>Fake</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>id16_id3_0007.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.295902</td>\n",
       "      <td>Fake</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>id2_id4_0003.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.262514</td>\n",
       "      <td>Fake</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>id2_id17_0006.mp4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.283234</td>\n",
       "      <td>Fake</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>id17_id2_0003.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293035</td>\n",
       "      <td>Fake</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name Blinks  Average_EAR FakeOReal Duration\n",
       "0      id1_id3_0004.mp4     12     0.262394      Fake       13\n",
       "1      id3_id6_0008.mp4      1     0.294461      Fake       15\n",
       "2      id4_id2_0009.mp4      8     0.300553      Fake       16\n",
       "3      id9_id2_0007.mp4      9     0.261735      Fake       15\n",
       "4    id13_id10_0000.mp4      1     0.380302      Fake       10\n",
       "..                  ...    ...          ...       ...      ...\n",
       "764   id3_id17_0005.mp4     11     0.244996      Fake       13\n",
       "765   id16_id3_0007.mp4      4     0.295902      Fake        9\n",
       "766    id2_id4_0003.mp4      7     0.262514      Fake       12\n",
       "767   id2_id17_0006.mp4      9     0.283234      Fake       12\n",
       "768   id17_id2_0003.mp4      1     0.293035      Fake        8\n",
       "\n",
       "[769 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('DF-synthesis.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
