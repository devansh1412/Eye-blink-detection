{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Video Detection using eye blinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"Notebook.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate eye aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distance between the vertical eye landmarks\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal eye landmarks\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the EAR\n",
    "    ear = (A + B) / (2 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EYE_AR_THRESH = 0.22\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "EAR_AVG = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize dlib's face detector (HOG-based) and then create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blinks(video):\n",
    "    # eye features regions\n",
    "    RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "    LEFT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "\n",
    "    COUNTER = 0\n",
    "    TOTAL = 0\n",
    "\n",
    "    # to detect the facial region\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(os.path.join(os.path.dirname(notebook_path), \"shape_predictor_68_face_landmarks.dat\"\n",
    "    ))\n",
    "    # capture frame from local video\n",
    "    # cap = cv2.VideoCapture(\"Home/Eye-detect-from-frame/download.jpeg\")\n",
    "    # capture video from live facecam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap = cv2.VideoCapture(os.path.join(os.path.dirname(notebook_path), video))\n",
    "\n",
    "    while True:\n",
    "        # get the frame\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        if frame is not []:\n",
    "            # convert the frame to grayscale\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                print(str(TOTAL)+\" blinks found\")\n",
    "                return TOTAL\n",
    "                cv2.destroyAllWindows()\n",
    "                break;\n",
    "            # get the facial regions\n",
    "            rects = detector(gray, 0)\n",
    "            # loop through each of the facial regions\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                x1 = rect.right()\n",
    "                y1 = rect.bottom()\n",
    "                # get the facial landmarks\n",
    "                landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "                # get the left eye landmarks\n",
    "                left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "                # get the right eye landmarks\n",
    "                right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "                # draw contours on the eyes\n",
    "                left_eye_hull = cv2.convexHull(left_eye)\n",
    "                right_eye_hull = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "                # compute the EAR for the left eye\n",
    "                ear_left = eye_aspect_ratio(left_eye)\n",
    "                # compute the EAR for the right eye\n",
    "                ear_right = eye_aspect_ratio(right_eye)\n",
    "                # compute the average EAR\n",
    "                ear_avg = (ear_left + ear_right) / 2.0\n",
    "                # detect the eye blink\n",
    "                if ear_avg < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "                else:\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        TOTAL += 1\n",
    "\n",
    "                    COUNTER = 0\n",
    "\n",
    "                cv2.putText(frame, \"Blinks {}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "                cv2.putText(frame, \"EAR {}\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "            cv2.imshow(\"Winks Found\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            # When key 'Q' is pressed, exit\n",
    "            if key is ord('q'):\n",
    "                print(TOTAL)\n",
    "                break\n",
    "        else:\n",
    "            cv2.destroyAllWindows()\n",
    "    # release all resources\n",
    "    cv2.waitKey(0)\n",
    "    # destroy all windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 blinks found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_blinks(\"vid.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
